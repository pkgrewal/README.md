# README.md
# README: Data Cleaning for July, August, and September 2024 Datasets
#This code cleans three datasets (July-September 2024) through functions such as standardizing column names, formatting dates, and handling missing values. It then exports the cleaned file as a CSV.

Thought Process
#I used the pandas library as it is something I have used  when it comes to working with data manipulation. I find it very straightforward to work with spreadsheets, and practical to transform an erroenous format to a much cleaner and simpler one. Additionally, pandas are very helpful when it comes to exporting CSV files. It easily handled all the variant types of data in the given spreadsheets.I carefully seperated each task given in the assignment into seperate functions. This way, if one wanted to clean a data sheet but perform a very specific one of these functions, for example, combining the reporting month and year into one report date, they could just find and run the def create_report_date(df) rather than loop through the whole code. I found that this approach helped me stay very organized and create a structured execution. Calling all the functions at the end also ensured I had done all the cleaning speficiations. 

Assumptions
#I assumed that the column names were standardly formatted across the three data spreadsheets, and the functions I was writing would be effective on each of them. I figured that although the data itself differs, the column names and datatypes were uniform across the three datasets. However, I found myself causing errors that would affect one spreadsheet differently than the others, and had to revaluate this assumption.

Issues Encountered
#I had an issue with the jurisdiction name cleaning (trying to get anything after the county name removed), as there was some differences in punctuation. For example, Santa Clara kept disappearing even after I thought I had successfully created the for loop, but after a little while, I realized the title was using a different type of apostrophe. Another issue I faced was when converting the numerical and non numerical columns, as I had trouble evaluating the different data types of the columns across the three spreadsheets. After trial and error, I found the way to tackle my issue with np.nan to be the df.replace function, and just specifying which values I saw were not numeric, something I hope to learn to generalize better for future datasets. The functions that would work for one of the month spreadsheets, then would not work on another. For example, for the date_of_highest_pop conversion to datetime, I had to really simplify down to recognition of that column, and then converting that column, because prior to that, I was attempting something related to its datatype, and the column would become blank for August and September only. 

Verifying Accuracy
#To verify the accuracy of my results, I referenced the panda libary documentation if necessary, ensuring I was correctly implementing the various functions. I ran tests on each of the different excel sheets multiple times, both individually, and then also exporting the three at once. I went through the original excel sheet and did a side by side comparison with the new CSV outputted, to ensure I had not removed or changed any important data or columns. I also referenced the assignment to ensure every qualification was met in the most efficient and clean way possible, even when it meant doing the given tasks out of order.

